{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "from chromadb.utils import embedding_functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma_client = chromadb.Client()\n",
    "client_persistent = chromadb.PersistentClient(path='/home/egarces/chatbot/databases/embeddings-public')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_transformer_ef = embedding_functions.SentenceTransformerEmbeddingFunction(model_name=\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Collection(id=2157830b-58d1-4df4-af31-20a1e593da24, name=langchain)]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client_persistent.list_collections()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = client_persistent.get_or_create_collection(name='langchain', embedding_function=sentence_transformer_ef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': ['2d23ddd2-e2d6-11ee-b3e0-b9320b25b112'],\n",
       " 'embeddings': array([[-5.15644476e-02, -5.58340317e-03,  9.14661735e-02,\n",
       "          7.76682124e-02,  2.59677142e-01,  3.59709598e-02,\n",
       "          2.96066813e-02,  9.95760933e-02, -1.91513687e-01,\n",
       "         -6.49192482e-02,  7.39299580e-02, -2.54625320e-01,\n",
       "          1.87229231e-01,  3.27701159e-02, -3.77930626e-02,\n",
       "         -5.52089997e-02,  7.65995979e-02, -6.35847375e-02,\n",
       "         -5.15189394e-02,  8.01788494e-02,  1.56739667e-01,\n",
       "         -1.91984907e-01, -7.16559067e-02,  2.28334770e-01,\n",
       "         -1.95928171e-01, -2.25191507e-02, -1.55682176e-01,\n",
       "          6.61088377e-02,  1.07859507e-01, -1.79414764e-01,\n",
       "         -9.47954059e-02,  1.68424815e-01, -2.30620250e-01,\n",
       "         -2.81535357e-01,  1.59576550e-01, -8.16967487e-02,\n",
       "         -2.04534624e-02,  1.67793185e-02, -1.68097749e-01,\n",
       "         -9.94877983e-03,  3.52992527e-02, -7.71250203e-02,\n",
       "          1.42698422e-01, -1.86311025e-02, -1.77909419e-01,\n",
       "         -8.91768560e-02,  1.13195434e-01,  1.23312943e-01,\n",
       "         -6.50090203e-02, -1.10665254e-01, -1.31587073e-01,\n",
       "          8.67962986e-02, -2.37478148e-02, -1.67870358e-01,\n",
       "          5.73772453e-02,  1.14740364e-01, -1.64836366e-02,\n",
       "          4.27315272e-02,  2.73618195e-02, -8.28843489e-02,\n",
       "         -1.14013314e-01, -8.27792957e-02, -2.65130609e-01,\n",
       "         -6.39296547e-02,  4.40901309e-01, -2.17071205e-01,\n",
       "         -3.92055735e-02, -3.95561643e-02,  3.25634092e-01,\n",
       "          2.26658091e-01, -7.64416605e-02,  2.18813140e-02,\n",
       "          2.31719807e-01,  1.21129602e-02,  6.01256676e-02,\n",
       "          1.63292751e-01, -2.07573384e-01, -4.34098728e-02,\n",
       "          1.54918507e-01, -1.73767403e-01,  9.52490047e-02,\n",
       "         -1.36868015e-01, -7.03023523e-02, -3.47931869e-02,\n",
       "          1.11690633e-01, -1.24257661e-01,  9.22233425e-03,\n",
       "          7.59265274e-02,  2.23753485e-03,  2.33168551e-03,\n",
       "          2.75479704e-01, -7.92958662e-02, -2.77403593e-02,\n",
       "          3.99565175e-02, -4.30221000e-04,  3.92796360e-02,\n",
       "         -1.24760769e-01,  3.71265598e-02,  1.75828055e-01,\n",
       "          2.21819252e-01, -1.27958164e-01, -1.36638865e-01,\n",
       "         -2.76862979e-01, -1.37893900e-01,  6.53733462e-02,\n",
       "         -3.00536186e-01, -8.42400417e-02, -2.28641406e-01,\n",
       "          1.71114847e-01,  7.43304268e-02,  9.64383706e-02,\n",
       "         -1.45320296e-02,  2.61300266e-01, -6.59144148e-02,\n",
       "          1.26817077e-03,  4.60656211e-02,  2.41955563e-01,\n",
       "         -1.99550003e-01, -5.69212437e-02, -1.38570771e-01,\n",
       "         -1.09332185e-02, -1.32950321e-01,  2.39699155e-01,\n",
       "          1.78415820e-01,  7.56300837e-02,  6.08440563e-02,\n",
       "         -1.29899874e-01, -1.94388628e-01, -3.13056000e-02,\n",
       "         -3.66756141e-01,  2.33094722e-01, -2.94707507e-01,\n",
       "         -2.00077161e-01,  5.00890873e-02, -7.55516812e-02,\n",
       "         -9.09173489e-02,  1.13153771e-01, -1.22415483e-01,\n",
       "          1.00316547e-01,  1.55709490e-01,  1.31281987e-01,\n",
       "          1.96399406e-01,  1.54500887e-01,  1.61087468e-01,\n",
       "          5.45214117e-02,  1.96246639e-01, -8.78076553e-02,\n",
       "         -3.00976504e-02, -1.51652144e-02, -1.90460891e-01,\n",
       "         -9.16202441e-02, -1.47349313e-01, -2.39439875e-01,\n",
       "         -3.04546170e-02, -3.64483632e-02,  2.04357728e-01,\n",
       "          3.93825546e-02,  4.51460816e-02,  1.81105025e-02,\n",
       "         -2.00327799e-01, -1.17876813e-01,  1.53921887e-01,\n",
       "         -3.11673641e-01,  8.31547156e-02,  2.29346722e-01,\n",
       "         -9.22915805e-03, -1.17248870e-01, -1.40530676e-01,\n",
       "          2.16565970e-02,  1.50993600e-01,  1.40169710e-01,\n",
       "         -1.22675695e-01, -1.09977759e-01, -3.08000594e-01,\n",
       "         -3.29146445e-01,  6.04369715e-02, -1.19735770e-01,\n",
       "         -1.56647921e-01,  5.96864484e-02, -7.72412773e-03,\n",
       "          1.38620451e-01, -2.00650357e-02, -1.08578339e-01,\n",
       "          1.57353710e-02, -2.16241717e-01, -6.70686597e-03,\n",
       "         -7.53874630e-02, -1.37716845e-01, -1.31585032e-01,\n",
       "          1.88368842e-01, -3.12416166e-01, -1.64321095e-01,\n",
       "          2.18621477e-01,  3.98111910e-01, -8.33090320e-02,\n",
       "         -7.85156270e-04,  1.17019296e-01, -1.14805520e-01,\n",
       "          3.56723070e-02,  1.00036323e-01,  4.84184138e-02,\n",
       "          1.19219743e-01,  2.57571787e-01, -1.56706229e-01,\n",
       "         -2.54281610e-01,  5.12415655e-02,  2.15980902e-01,\n",
       "         -1.72210917e-01,  2.14111820e-01,  1.41757190e-01,\n",
       "         -1.54520795e-01,  2.85941754e-02,  8.98722280e-03,\n",
       "         -3.57413560e-01,  9.89767760e-02, -9.72133316e-03,\n",
       "         -8.99989456e-02,  1.25822335e-01, -1.04832388e-01,\n",
       "          8.45643654e-02, -7.41755962e-02,  1.99769765e-01,\n",
       "          1.84267059e-01, -4.36678044e-02, -3.85851115e-01,\n",
       "          2.11770162e-01, -4.76207060e-04,  6.20876737e-02,\n",
       "         -2.11592346e-01,  1.77049249e-01,  1.68507770e-01,\n",
       "         -3.19922715e-01,  4.18329686e-01, -1.21699825e-01,\n",
       "          2.30044685e-02, -1.60379410e-01,  3.24727618e-03,\n",
       "          2.61611670e-01, -1.03617013e-02, -1.73850760e-01,\n",
       "         -2.95355022e-01, -2.98317783e-02, -1.43583983e-01,\n",
       "         -2.35704165e-02, -1.59436703e-01,  3.08810771e-01,\n",
       "          1.72303170e-02,  9.28445607e-02, -2.06576899e-01,\n",
       "         -1.70366436e-01,  2.36537859e-01,  1.01439618e-01,\n",
       "          1.34344399e-01, -4.20787632e-02,  9.30872113e-02,\n",
       "          2.09397361e-01, -2.04659015e-01,  4.18958873e-01,\n",
       "         -1.79955084e-02,  1.91366181e-01,  2.55254805e-01,\n",
       "          7.08253458e-02, -1.98100824e-02,  5.16207576e-01,\n",
       "         -1.22384295e-01,  1.45057186e-01, -2.51920491e-01,\n",
       "         -2.53057569e-01, -3.78298834e-02, -6.66429568e-03,\n",
       "          5.56502305e-02, -2.63515025e-01,  2.40114614e-01,\n",
       "         -6.09777495e-02, -8.28292519e-02, -2.92921007e-01,\n",
       "         -1.39578015e-01,  1.93401814e-01, -1.66869536e-01,\n",
       "          5.48309013e-02,  2.90701091e-01,  2.99129754e-01,\n",
       "          1.58229440e-01,  1.24007225e-01, -8.57206210e-02,\n",
       "          5.58352144e-03,  1.21027008e-02, -4.21280921e-01,\n",
       "          1.17785290e-01,  3.31655666e-02, -5.70595674e-02,\n",
       "         -4.21769880e-02,  3.37992698e-01, -2.70288944e-01,\n",
       "         -1.09728195e-01,  1.05058833e-03,  5.49029894e-02,\n",
       "         -7.17312619e-02,  2.55165607e-01,  8.06201249e-02,\n",
       "         -8.62004608e-02,  2.96581328e-01, -9.67787877e-02,\n",
       "          5.79785444e-02,  2.14953899e-01,  9.17804614e-02,\n",
       "          8.66220966e-02,  2.82987863e-01,  1.78252950e-01,\n",
       "         -1.55820221e-01,  1.42518401e-01, -2.34407097e-01,\n",
       "         -2.25129947e-01,  1.74724355e-01,  1.13882557e-01,\n",
       "         -4.00471613e-02,  3.09766475e-02,  1.17918499e-01,\n",
       "         -1.10314945e-02,  2.02325910e-01, -6.16804585e-02,\n",
       "         -4.60708700e-02,  4.20453884e-02,  1.02635980e-01,\n",
       "          8.46268758e-02,  3.31810340e-02, -1.53887719e-01,\n",
       "         -1.38152819e-02, -1.89350918e-01, -1.09165266e-01,\n",
       "         -1.75661370e-01,  2.06933051e-01, -1.85298100e-01,\n",
       "          7.01888651e-02, -9.90088582e-02, -2.11434394e-01,\n",
       "         -1.21320225e-01,  2.08377808e-01, -7.52955452e-02,\n",
       "         -4.73646633e-02,  1.36101082e-01,  1.45322233e-02,\n",
       "         -6.13345578e-02,  7.77669698e-02, -8.51294845e-02,\n",
       "         -1.52269945e-01, -4.13934560e-03,  1.89115778e-01,\n",
       "         -1.42455086e-01, -4.01311591e-02,  2.42275864e-01,\n",
       "          2.05140322e-01,  5.60763404e-02,  1.02924846e-01,\n",
       "          1.15516141e-01,  2.71599982e-02, -4.83788475e-02,\n",
       "         -4.57379445e-02, -1.72161222e-01,  2.18138367e-01,\n",
       "          1.44622013e-01, -1.80231422e-01, -1.87468275e-01,\n",
       "         -6.41967133e-02, -1.89808011e-01,  8.69015604e-02,\n",
       "          1.25734702e-01,  1.34347573e-01,  9.93099213e-02,\n",
       "         -2.47608889e-02, -1.52180105e-01,  4.46771793e-02,\n",
       "         -1.45301789e-01, -1.91406563e-01, -1.19540710e-02,\n",
       "         -8.74923691e-02,  1.55822262e-01, -3.09079707e-01,\n",
       "          1.21740930e-01, -1.18761940e-03, -5.14593981e-02,\n",
       "          2.57772356e-01,  1.62887368e-02,  1.75769612e-01]]),\n",
       " 'documents': ['Ajustado error cuando se usaban suggest en el filtro no traía resultadosPruebas y aplicabilidad: Makro y dónde aplique, se debe probar que al usar en el filtro campos suggest, este retorne los resultados que corresponden al filtro aplicado.'],\n",
       " 'uris': None,\n",
       " 'data': None,\n",
       " 'metadatas': [{'source': 122430}],\n",
       " 'included': [<IncludeEnum.embeddings: 'embeddings'>,\n",
       "  <IncludeEnum.documents: 'documents'>,\n",
       "  <IncludeEnum.metadatas: 'metadatas'>]}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.peek(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete info by element\n",
    "\n",
    "element_id = 'ElementId'\n",
    "db.delete(where={\"source\": {\"$eq\": element_id}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add info by element based\n",
    "\n",
    "\n",
    "\"\"\" \n",
    "JSON Structure\n",
    "\n",
    "{\n",
    "    \"source\" : ElementId,\n",
    "    \"document\" : \"la historia de la vida\"  # relevant info\n",
    "    \"keywords\": [\"word1\", \"word2\"]\n",
    "}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "# documents = [\"Este es el tercer documento \"]\n",
    "# metadatas = [\n",
    "#     {\"source\": element_id}\n",
    "# ]\n",
    "\n",
    "# # Genera IDs automáticamente\n",
    "# ids = [str(uuid.uuid4()) for _ in documents]\n",
    "\n",
    "# # Agrega los documentos a la colección\n",
    "# db.add(ids=ids, documents=documents, metadatas=metadatas)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "# Configuración del modelo de Sentence Transformers\n",
    "model = SentenceTransformer('sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplo de JSON\n",
    "data = {\n",
    "    \"source\": \"ElementId\",\n",
    "    \"document\": \"la historia de la vida es larga y llena de eventos. A través del tiempo, muchas culturas han dejado huellas en la historia...\",  # texto de ejemplo\n",
    "    \"keywords\": [\"historia\", \"vida\", \"cultura\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'source': 'ElementId'}, {'source': 'ElementId'}, {'source': 'ElementId'}, {'source': 'ElementId'}, {'source': 'ElementId'}]\n",
      "['este es un ejemplo de texto que queremos divid word1  word2', 'dividir en fragmentos basados en tokens. el solapamiento word1  word2', '##apamiento asegura que haya contexto compartido entre word1  word2', 'entre los fragmentos. es una forma util de preproces word1  word2', '##rocesar texto para modelos como los de sentence - transformers. word1  word2']\n",
      "['01022da5-df88-4eff-baf3-91856ff80110', 'c3bf9d1d-030a-4fcf-bde1-1b08b4020471', '4c0b0650-36e7-4552-852b-7daedb4bd45e', '12b8a199-a2cb-467e-a6d5-fac25a74c3e8', '99259091-be1d-4b44-a3ae-ac0b1265ec72']\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import uuid\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "\n",
    "def split_text_by_tokens_transformers(text, max_tokens, overlap=0, model_name=\"sentence-transformers/all-MiniLM-L6-v2\"):\n",
    "    \"\"\"\n",
    "    Divide un texto en fragmentos basados en tokens, compatible con modelos de sentence-transformers.\n",
    "\n",
    "    Args:\n",
    "        text (str): Texto a dividir.\n",
    "        max_tokens (int): Número máximo de tokens por fragmento.\n",
    "        overlap (int): Número de tokens solapados entre fragmentos.\n",
    "        model_name (str): Modelo de transformers para determinar el tokenizador.\n",
    "\n",
    "    Returns:\n",
    "        List[str]: Lista de fragmentos de texto.\n",
    "    \"\"\"\n",
    "    # Validar el solapamiento\n",
    "    if overlap >= max_tokens:\n",
    "        raise ValueError(\"El solapamiento debe ser menor que el número máximo de tokens.\")\n",
    "    \n",
    "    # Inicializar el tokenizador\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    \n",
    "    # Tokenizar el texto (convertir a lista de tokens)\n",
    "    encoded_input = tokenizer(text, truncation=False, padding=False, add_special_tokens=False)\n",
    "    \n",
    "    # Verificar si la tokenización fue exitosa\n",
    "    if \"input_ids\" not in encoded_input:\n",
    "        raise ValueError(\"La tokenización ha fallado, no se generaron 'input_ids'.\")\n",
    "    \n",
    "    tokens = encoded_input[\"input_ids\"]\n",
    "    \n",
    "    # Si el texto es más pequeño que el máximo de tokens, no es necesario dividir\n",
    "    if len(tokens) <= max_tokens:\n",
    "        return [tokenizer.decode(tokens, skip_special_tokens=True)]\n",
    "    \n",
    "    # Dividir en fragmentos\n",
    "    chunks = []\n",
    "    start = 0\n",
    "    while start < len(tokens):\n",
    "        # Si estamos en el último fragmento, no hay necesidad de avanzar más allá de los tokens disponibles\n",
    "        end = min(start + max_tokens, len(tokens))\n",
    "        chunk_tokens = tokens[start:end]\n",
    "        chunk_text = tokenizer.decode(chunk_tokens, skip_special_tokens=True)\n",
    "        chunks.append(chunk_text)\n",
    "        \n",
    "        # Si no hay suficiente espacio para el solapamiento, terminamos\n",
    "        if end == len(tokens):\n",
    "            break\n",
    "        \n",
    "        start = end - overlap  # Retroceder para el solapamiento\n",
    "    return chunks\n",
    "\n",
    "\n",
    "\n",
    "# Función para crear el JSON particionado\n",
    "def partition_json(data, max_tokens=20, overlap_tokens=2):\n",
    "    # Particionar el texto en fragmentos\n",
    "\n",
    "    keywords_unificado = \"  \".join(data[\"keywords\"])\n",
    "\n",
    "    # Inicializar el tokenizador\n",
    "    tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/all-MiniLM-L6-v2')\n",
    "    \n",
    "    # Tokenizar el texto (convertir a lista de tokens)\n",
    "    encoded_input = tokenizer(keywords_unificado, truncation=False, padding=False, add_special_tokens=False)\n",
    "    \n",
    "    # Verificar si la tokenización fue exitosa\n",
    "    if \"input_ids\" not in encoded_input:\n",
    "        raise ValueError(\"La tokenización ha fallado, no se generaron 'input_ids'.\")\n",
    "    \n",
    "    tokens = encoded_input[\"input_ids\"]\n",
    "\n",
    "    partitions = split_text_by_tokens_transformers(data[\"document\"], max_tokens-len(tokens), overlap_tokens)\n",
    "    #partitions=['prueba 1', 'prueba 2']#data[\"document\"]\n",
    "    #print(partitions)\n",
    "    # # Crear el nuevo JSON con los fragmentos\n",
    "    partitioned_data = []\n",
    "    for i, partition in enumerate(partitions):\n",
    "\n",
    "        #print(partition)\n",
    "        partitioned_data.append({\n",
    "            \"source\": data[\"source\"],\n",
    "            \"document\": partition + ' ' + keywords_unificado,  # Reconstruir el fragmento de texto\n",
    "            \"keywords\": data[\"keywords\"],\n",
    "        })\n",
    "    \n",
    "    return partitioned_data\n",
    "\n",
    "# Ejemplo de datos originales\n",
    "data = {\n",
    "    \"source\": \"ElementId\",\n",
    "    \"document\": \"Este es un ejemplo de texto que queremos dividir en fragmentos basados en tokens. El solapamiento asegura que haya contexto compartido entre los fragmentos. Es una forma útil de preprocesar texto para modelos como los de sentence-transformers.\",\n",
    "    \"keywords\": [\"word1\", \"word2\"]\n",
    "}\n",
    "\n",
    "# Particionar el JSON\n",
    "partitioned_json = partition_json(data)\n",
    "#print(partitioned_json)\n",
    "\n",
    "# Imprimir el JSON particionado\n",
    "#print(json.dumps(partitioned_json))\n",
    "# Generar la lista formateada\n",
    "sources = [{\"source\": item['source']} for item in partitioned_json]\n",
    "\n",
    "\n",
    "documents = [item['document'] for item in partitioned_json]\n",
    "\n",
    "# Genera IDs automáticamente\n",
    "ids = [str(uuid.uuid4()) for _ in documents]\n",
    "\n",
    "\n",
    "# Imprimir el resultado\n",
    "print(sources)\n",
    "print(documents)\n",
    "print(ids)\n",
    "\n",
    "# Agrega los documentos a la colección\n",
    "db.add(ids=ids, documents=documents, metadatas=sources)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': [['12b8a199-a2cb-467e-a6d5-fac25a74c3e8',\n",
       "   '01022da5-df88-4eff-baf3-91856ff80110',\n",
       "   'c3bf9d1d-030a-4fcf-bde1-1b08b4020471',\n",
       "   '4c0b0650-36e7-4552-852b-7daedb4bd45e',\n",
       "   '99259091-be1d-4b44-a3ae-ac0b1265ec72']],\n",
       " 'embeddings': None,\n",
       " 'documents': [['entre los fragmentos. es una forma util de preproces word1  word2',\n",
       "   'este es un ejemplo de texto que queremos divid word1  word2',\n",
       "   'dividir en fragmentos basados en tokens. el solapamiento word1  word2',\n",
       "   '##apamiento asegura que haya contexto compartido entre word1  word2',\n",
       "   '##rocesar texto para modelos como los de sentence - transformers. word1  word2']],\n",
       " 'uris': None,\n",
       " 'data': None,\n",
       " 'metadatas': [[{'source': 'ElementId'},\n",
       "   {'source': 'ElementId'},\n",
       "   {'source': 'ElementId'},\n",
       "   {'source': 'ElementId'},\n",
       "   {'source': 'ElementId'}]],\n",
       " 'distances': [[23.348649631292297,\n",
       "   26.09077413200531,\n",
       "   28.330692514083804,\n",
       "   28.996867100705746,\n",
       "   30.45221425930692]],\n",
       " 'included': [<IncludeEnum.distances: 'distances'>,\n",
       "  <IncludeEnum.documents: 'documents'>,\n",
       "  <IncludeEnum.metadatas: 'metadatas'>]}"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#List by elementId \n",
    "\n",
    "\n",
    "resultados = db.query(\n",
    "    query_texts=[\"\"], \n",
    "    where={\n",
    "        \"source\": {\"$eq\": 'ElementId'},\n",
    "    },\n",
    "    n_results=10  # Especifica el número de resultados que deseas obtener\n",
    ")\n",
    "resultados"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
